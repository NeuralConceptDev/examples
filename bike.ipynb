{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NeuralConceptDev/examples/blob/master/bike.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing the Neural Concept API\n",
    "\n",
    "Neural Concept provides APIs for training 3D deep learning models that learn to predict engineering simulations of different physical processes. In this tutorial, we are going to show how one of our pre-trained models can be used for making predictions on the 3D model of a bike. At the end of the tutorial, you will learn to -\n",
    "\n",
    "* explore the public datasets on our platform\n",
    "* use the public pre-trained models to perform predictions\n",
    "* learn about the more advanced features of our platform.\n",
    "\n",
    "To get started, visit https://prod.neuralconcept.com/register and create an account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "In this section, we install the required packages and setup our credentials to use the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the ncapi client\n",
    "!pip install -U ncapi-client\n",
    "# Install plotly for visualizations\n",
    "! pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"NCAPI_URL\"] = \"https://prod.neuralconcept.com\"\n",
    "os.environ[\"NCAPI_USERNAME\"] = \"<INSERT USERNAME>\"\n",
    "os.environ[\"NCAPI_PASSWORD\"] = \"<INSERT PASSWORD>\"\n",
    "\n",
    "from ncapi_client.client import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The public bike Dataset\n",
    "\n",
    "Lets list the available datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All users of our platform have access to a dataset of bike designs. <Insert history>.\n",
    "\n",
    "Lets get some more details about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ncapi_client.dataset import Dataset\n",
    "bike_dataset = Dataset(client, \"bike-demo\")\n",
    "bike_dataset.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset info provides detailed information about the dataset. The \"data_format\" attribute indicates the current format of the dataset, and the formats are the list of formats available for the dataset. The \"raw\" format is the format that user is expected to upload the data in, we will get into the details of the format in a more advanced notebook. The \"npy_indiv\" format is a serialized numpy array format, which is ready to be fed into a deep learning model. The status of \"CONVERTED\" indicates that this dataset has been converted from \"raw\" to \"npy_indiv\" format.\n",
    "\n",
    "Now let us look into some samples present in the dataset. The samples attributes returns the list of sample ids the dataset contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_dataset.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = bike_dataset.sample(\"0000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"verts\", \"adj\" and \"faces\" attributes describe the 3D shape. The \"output_fields\" and \"output_scalars\" are the labels for the sample ( i.e. the variable which the model tries to predict) . Some datasets can also have a \"input_fields\" and \"input_scalars\" attribute, which represent inputs to the model in addition to the shape information.\n",
    "\n",
    "To get a better feel for the problem, lets visualize this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "\n",
    "def visualize_sample(sample, predictions=None):\n",
    "    verts = np.array(sample[\"verts\"])\n",
    "    faces = np.array(sample[\"faces\"])\n",
    "    preds = predictions[\"output_fields\"][0, ...] if predictions else np.array(sample[\"output_fields\"])\n",
    "    x, y, z = verts[:,0], verts[:,1], verts[:,2]\n",
    "    I, J, K = faces[:,0], faces[:,1], faces[:,2]\n",
    "    preds = np.clip(preds, -0.5, 0.5)\n",
    "    trace = go.Mesh3d(x=x,y=y,z=z,i=I,j=J,k=K,intensity=preds[:,0])\n",
    "    return go.Figure(data=[trace], layout=go.Layout(scene=dict(aspectmode=\"data\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_sample(sample).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization shows the 3D model of the bike. The output_field values are shown in the color scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Public Trained Models\n",
    "\n",
    "Next lets look at the available pre-trained model that can be used to get predictions on our bike shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ncapi_client.trained_model import TrainedModel\n",
    "bike_model = TrainedModel(client, \"bike-demo-model.ckpt-103600\")\n",
    "bike_model.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The checkpoint_id attribute is checkpoint step in the training process from which this trained model was created. The class_name is the underlying python class which encapsulates this model and defines its network architecture. The config parameters are additional attributes that define the model for a specific dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting a prediction Job and get predictions\n",
    "\n",
    "In this section, we will see how to submit a prediction job using the bike dataset and model we saw in the previous sections. \n",
    "\n",
    "To submit a prediction job, we need the trained model id, the dataset id and a list of samples for which we want the predictions. Lets submit the first 10 samples of the dataset as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ncapi_client.prediction import Prediction\n",
    "\n",
    "pred = Prediction.submit(client, bike_model.info.uuid, \n",
    "                         dataset_id=bike_dataset.info.uuid, \n",
    "                         sample_ids=bike_dataset.samples[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A prediction job has now been created. Behind the scenes, the API will spin up a prediction worker, pull the dataset samples and the model and calculate the predictions. This may take upto 10-15 minutes, as in some cases it may involve provisioning a new virtual machine with GPUs installed. When the job has finished, the status of te Job will change to finished.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while pred.info.status != \"FINISHED\":\n",
    "    print(\".\", end=\"\")\n",
    "print(\"Job finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now fetch the predictions and compare with the ground truth labels. To get the predictions, we pass in a list of sample ids. This may take a while, as the predictions are fetched one by one. We are coming up soon with a batch API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pred.get_results(bike_dataset.samples[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualize the predictions for the first sample and compare with the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_sample(results[0].sample, results[0].prediction).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_sample(sample).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running an interactive session\n",
    "\n",
    "In addition to submitting a prediction job, you can also create a prediction endpoint to get realtime predictions. You can use this feature to interatively make changes to your design and get immediate feedback in the form of how your changes affect the prediction.\n",
    "\n",
    "To start an interactive session, you need a trained model and a dataset sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ncapi_client.session import Session\n",
    "\n",
    "sess = Session.start(client, bike_model.info.uuid, bike_dataset.info.uuid, bike_dataset.samples[0], socket_params=dict(max_size=2**24))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to batch prediction, an interactive session may also involve provisioning a new instance and may take upto 10-15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interactive session can be viewed in the following url -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"https://staging.neuralconcept.com/viewer/session/{sess.info.id}?jwt={client.access_token}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete()\n",
    "pred.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we showcased how the Neural Concept API can be used for getting batch and interactive predictions on 3D models. \n",
    "In a follow up example, we will show how you can bring your data and create your own trained models and use them for predictions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
