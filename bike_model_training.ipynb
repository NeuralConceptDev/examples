{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NeuralConceptDev/examples/blob/master/bike_model_training.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing\n",
    "\n",
    "Neural Concept provides APIs for training 3D deep learning models that learn to predict engineering simulations of different physical processes. In the [first tutorial]([https://github.com/NeuralConceptDev/examples/blob/master/bike.ipynb]) , we showed how to perform predictions using a publicly available pretrained model.\n",
    "\n",
    "In this tutorial, we are going to show how to bring your own data and train your your own models in the neural concept platform. By the end of the tutorial you will learn -\n",
    "\n",
    "* the dataset formats and how to upload your training data.\n",
    "* model configurations and how to create a model definition.\n",
    "* to start a training job.\n",
    "* save a training checkpoint to create a trained model.\n",
    "\n",
    "To get started, visit https://cloud.neuralconcept.com/register and create an account. You will need a member account to perform this tutorial, which you can have by requesting the free upgrade of your account for 14 days! You can also drop an email to contact@neuralconcept.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "In this section, we install the required packages and setup our credentials to use the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the ncapi client\n",
    "pip install -U ncapi-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"NCAPI_URL\"] = \"https://cloud.neuralconcept.com\"\n",
    "\n",
    "os.environ[\"NCAPI_USERNAME\"] = \"<INSERT USERNAME>\"\n",
    "\n",
    "pwd=getpass.getpass(prompt='Enter your NCAPI password: ', stream=None) \n",
    "os.environ[\"NCAPI_PASSWORD\"] = pwd\n",
    "\n",
    "from ncapi_client.client import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Formats\n",
    "\n",
    "In this section, we are going to look into details of how to prepare your data for training. To illustrate, we are going to use the same bike dataset from the previously tutorial.\n",
    "\n",
    "First lets download the dataset from the public google cloud storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp -r gs://nc-public-examples/datasets/bike/ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of three types of files - .stl , .csv and .json . For each type, there are 90 files. Each tuple  (geometry_<>.stl, output_fields_<>.csv, output_scalars_<>.json) represents a sample in the dataset.\n",
    "\n",
    "The stl file is a standard file format for representing the surface geometry of a 3D object. It represents the surface using a collection of vertices, and three tuples of vertices forming a triangle. Each vertex is a point in 3D co-ordinates.\n",
    "\n",
    "For example, lets look at the first few lines of the first sample -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head bike/raw/geometry_0000.stl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output field csv file contains information about the field values at vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head bike/raw/output_fields_0000.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here there are 7 different kind of field values present. \"p\" is the pressure field; Ux, Uy and Uz are the velocity in x,y and z direction respectively at the vertex defined by co-ordinates x,y,z.\n",
    "\n",
    "k is a variable representing the turbulence kinetic energy\n",
    "\n",
    "omega is the specific rate of dissipation \n",
    "\n",
    "nut is the Eddy viscosity \n",
    "\n",
    "The output scalars json file represent global outputs associated with the entire sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat bike/raw/output_scalars_0000.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we will train the model to predict these output fields and scalars from just the input geometry. In general, our platform also allows for supporting input fields and scalars, where the model learns to predict using both the geometry and the input fields and scalars.\n",
    "\n",
    "At the moment, we expect the data to be in this format of tuples of json, csv and stl files. We are working on integrations with more formats from your favorite simulation software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a dataset and uploading the data\n",
    "\n",
    "Once the dataset is prepared in the desired format, we can create a dataset through the ncapi client and upload the dataset files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ncapi_client.dataset import Dataset\n",
    "\n",
    "bike_dataset = Dataset.add(client, \n",
    "                           name=\"bike_dataset\",\n",
    "                           files=\"bike/raw\",\n",
    "                           split=0.9,\n",
    "                           max_degree=10\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the split parameter can be used to specify the split between training and validation (if not specified, this value is fixed to a default value of 0.75). The input geometry will be converted to an adjacency representation, and the max_degree parameter controls the maximum number of neighbors a vertex will have.\n",
    "\n",
    "When the upload completes, the system will automatically trigger a conversion job to convert the data to an internal format which suitable for feeding into the neural network model.\n",
    "\n",
    "The dataset conversion status can be checked by looking at the dataset info. The status will be marked as CONVERTED when the conversion process has finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_dataset.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The status of the conversion job itself can be checked with this helper function -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_dataset.get_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models \n",
    "\n",
    "Next we look at configuring a model for our training. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ncapi_client.model import Model\n",
    "model = Model.add(\n",
    "    client,\n",
    "    name='bike-model-config', \n",
    "    class_name='ncs.models.point_regressor.PointRegressor',\n",
    "    num_output_fields=7,\n",
    "    num_output_scalars=12, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class_name is the class of the model to use for training. \n",
    "The num_output_fields and num_output_scalars are the output fields and scalars in our dataset. We found these values from examining the dataset in the previous section.\n",
    "\n",
    "To view a list of all possible model configurations, refer to the python client api docs at https://storage.googleapis.com/nc-public-docs/ncapi-python-client/index.html \n",
    "For now, when creating a model from the python client (model.config), you are only able to access to the parameters that you changed, the other values are set to the default ones. If you want more options in customizing your model, we recommend that you use the GUI to create your model. From there, you will be able to see the whole config file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting a Training Job \n",
    "\n",
    "In this section, we will see how to submit a training job using the bike dataset we uploaded and the model configuration we created in the previous section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ncapi_client.training import Training\n",
    "\n",
    "training = Training.submit(client, \n",
    "                           model_id=model.info.uuid, \n",
    "                           dataset_id=bike_dataset.info.uuid,\n",
    "                           user_config=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view a list of all possible training job configurations, refer to the python client api docs \n",
    "at https://storage.googleapis.com/nc-public-docs/ncapi-python-client/index.html .\n",
    "\n",
    "A training job has now been created. Behind the scenes, the API will spin up a training worker running on a GPU instance, pull the dataset and the model configurations and start the training loop.\n",
    "\n",
    "The training status can be checked by calling info. We recommend that you monitor your training from the GUI as you can also start Tenserboard sessions to have a better overview of your training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default training continues to run for \"X\" number of stops. We can choose to stop the job before training completes using - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a trained model from a training\n",
    "\n",
    "The training job saves periodic checkpoints as it trains. We can create a trained model from these checkpoints.\n",
    "\n",
    "The checkpoints can be listed using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".To create a saved model from the checkpoint at step 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = training.save(checkpoint_id='model.ckpt-2000', name='trained_model_bike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the checkpoint is not specified, the save method creates a trained model based on the last checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_trained_model = training.save()\n",
    "latest_trained_model.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model can now be used for making batch predictions or starting an interactive session.\n",
    "\n",
    "It is also possible to download the trained model files for later use-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bike_trainied_model.tar.gz\", \"wb\") as f:\n",
    "    f.write(trained_model.download().read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvzf bike_trainied_model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These downloaded files can be used to create trained model later -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ncapi_client.trained_model import TrainedModel\n",
    "\n",
    "trained_model_copy = TrainedModel.add(\n",
    "    client,\n",
    "    f\"trained_model_bike_65ad6de0-6c98-4da1-8de2-19d6bb1013e0/config.yml\",\n",
    "    f\"trained_model_bike_65ad6de0-6c98-4da1-8de2-19d6bb1013e0/model.ckpt-2000\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_copy.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.delete()\n",
    "trained_model_copy.delete()\n",
    "latest_trained_model.delete()\n",
    "training.delete()\n",
    "bike_dataset.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we showcased how the Neural Concept API can be used for training a model using your own data using the bike dataset as an example.\n",
    "\n",
    "In a follow up tutorial, we will explore new dataset across different application areas, and also dive deep into how to customize the models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
